{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has Columns \n",
      "Index(['Purchase__basketValueGross', 'Purchase__purchaseType',\n",
      "       'Purchase__overallBasketSavings', 'Purchase__storeId',\n",
      "       'Purchase__paymentType__category', 'Purchase__paymentType__amount',\n",
      "       'Purchase__timeStamp', 'Purchase__basketValueNet', 'Purchase__says',\n",
      "       'Purchase__storeName', 'Purchase__storeFormat',\n",
      "       'Purchase__product__name', 'Purchase__product__quantity',\n",
      "       'Purchase__product__channel', 'Purchase__product__price'],\n",
      "      dtype='object')\n",
      "\n",
      "The CSV file has data types \n",
      "Purchase__basketValueGross          object\n",
      "Purchase__purchaseType              object\n",
      "Purchase__overallBasketSavings     float64\n",
      "Purchase__storeId                  float64\n",
      "Purchase__paymentType__category    float64\n",
      "Purchase__paymentType__amount      float64\n",
      "Purchase__timeStamp                 object\n",
      "Purchase__basketValueNet           float64\n",
      "Purchase__says                     float64\n",
      "Purchase__storeName                 object\n",
      "Purchase__storeFormat               object\n",
      "Purchase__product__name             object\n",
      "Purchase__product__quantity        float64\n",
      "Purchase__product__channel          object\n",
      "Purchase__product__price           float64\n",
      "dtype: object\n",
      "\n",
      "There are 444 rows and 15 columns in this Data frame currently\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "def read(file):\n",
    "  data = pd.read_csv(file)\n",
    "\n",
    "  print(\"CSV file has Columns \\n{}\".format(data.columns))\n",
    "  print(\"\\nThe CSV file has data types \\n{}\".format(data.dtypes))\n",
    "  print(f\"\\nThere are {data.shape[0]} rows and {data.shape[1]} columns in this Data frame currently\")\n",
    "\n",
    "  return data\n",
    "  \n",
    "data_file = read(\"DataAnalystTask.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforming the data\n",
    "## Clean up data, trim columns, filter and order it\n",
    "## Store name and timestamp have MNAR data\n",
    "## Gathering columns which are needed\n",
    "\n",
    "## This dataset has 430 unnamed stores which have been filled with Undesignated store and empty purchased timestamps which has been filled with the median of the dataset for timestamps\n",
    "## I have removed any data without any product names as well \n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# parsing duration as a timedelta\n",
    "def parse_duration(x):\n",
    "    try:\n",
    "        if pd.isna(x): return np.nan\n",
    "        mins, secs = x.split(':')\n",
    "        return timedelta(minutes=int(mins), seconds=float(secs))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def transform(data_file):\n",
    "    required_data = data_file[[\"Purchase__product__name\",\"Purchase__product__price\",\"Purchase__timeStamp\",\"Purchase__product__quantity\",\"Purchase__storeName\"]]\n",
    "\n",
    "    ## removing products without a product name (NaN)\n",
    "    required_data = required_data.dropna(subset=[\"Purchase__product__name\"])\n",
    "\n",
    "\n",
    "    #Adjusting the error in timestamp\n",
    "    required_data['Purchase__timeStamp'] = required_data['Purchase__timeStamp'].apply(parse_duration)\n",
    "    #getting the median excluding NAN\n",
    "    median_time = required_data[\"Purchase__timeStamp\"].median()\n",
    "    #filling the null values with median\n",
    "    required_data[\"Purchase__timeStamp\"] = required_data[\"Purchase__timeStamp\"].fillna(median_time)\n",
    "\n",
    "    df = pd.DataFrame(required_data)\n",
    "    #debug to find highest frequency of store names\n",
    "    #display(df.groupby('Purchase__storeName').count())\n",
    "\n",
    "    #Filling missing store names with store 'Undesignated store'\n",
    "    df[[\"Purchase__storeName\"]] = df[[\"Purchase__storeName\"]].fillna(\"Undesignated store\")\n",
    "    display(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has been loaded to sqlite\n",
      "\n",
      "Data in Store_Purchase table has been loaded successfuly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/gy8jzz9n1yx5nmwnqmqyckbc0000gn/T/ipykernel_91918/1149635945.py:10: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  dataframe.to_sql(name=table_name, con=con, if_exists=\"replace\", index=False)\n"
     ]
    }
   ],
   "source": [
    "## Loading the dataframe into a database\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "def load(dataframe, database_name, table_name):\n",
    "  #create the connection obj\n",
    "  con = sqlite3.connect(database_name)\n",
    "\n",
    "  #now we will write the data to a specific table which we have specified in the param\n",
    "  dataframe.to_sql(name=table_name, con=con, if_exists=\"replace\", index=False)\n",
    "  print(\"Dataframe has been loaded to sqlite\\n\")\n",
    "\n",
    "  # reading the data which has been loaded for validation\n",
    "  loaded_df = pd.read_sql(sql=f\"SELECT * FROM {table_name}\", con=con)\n",
    "\n",
    "  try:\n",
    "      #ensuring shape of DF loaded is same as what we have from the transformation stage\n",
    "      assert dataframe.shape == loaded_df.shape\n",
    "      print(f\"Data in {table_name} table has been loaded successfuly\")\n",
    "\n",
    "  except AssertionError:\n",
    "     print(f\"Error! Data in {table_name} table has not been loaded successfuly\")\n",
    "\n",
    "#calling function\n",
    "load(dataframe = df, database_name=\"Data_Pipeline\", table_name=\"Store_Purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has Columns \n",
      "Index(['Purchase__basketValueGross', 'Purchase__purchaseType',\n",
      "       'Purchase__overallBasketSavings', 'Purchase__storeId',\n",
      "       'Purchase__paymentType__category', 'Purchase__paymentType__amount',\n",
      "       'Purchase__timeStamp', 'Purchase__basketValueNet', 'Purchase__says',\n",
      "       'Purchase__storeName', 'Purchase__storeFormat',\n",
      "       'Purchase__product__name', 'Purchase__product__quantity',\n",
      "       'Purchase__product__channel', 'Purchase__product__price'],\n",
      "      dtype='object')\n",
      "\n",
      "The CSV file has data types \n",
      "Purchase__basketValueGross          object\n",
      "Purchase__purchaseType              object\n",
      "Purchase__overallBasketSavings     float64\n",
      "Purchase__storeId                  float64\n",
      "Purchase__paymentType__category    float64\n",
      "Purchase__paymentType__amount      float64\n",
      "Purchase__timeStamp                 object\n",
      "Purchase__basketValueNet           float64\n",
      "Purchase__says                     float64\n",
      "Purchase__storeName                 object\n",
      "Purchase__storeFormat               object\n",
      "Purchase__product__name             object\n",
      "Purchase__product__quantity        float64\n",
      "Purchase__product__channel          object\n",
      "Purchase__product__price           float64\n",
      "dtype: object\n",
      "\n",
      "There are 444 rows and 15 columns in this Data frame currently\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "#Extract data\n",
    "data_file = read(\"DataAnalystTask.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchase__product__name</th>\n",
       "      <th>Purchase__product__price</th>\n",
       "      <th>Purchase__timeStamp</th>\n",
       "      <th>Purchase__product__quantity</th>\n",
       "      <th>Purchase__storeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Koko Dairy Free Unsweetened Alternative Longli...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0 days 00:37:36.800000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SOUTHWARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesco Bunched Spring Onions 100G</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0 days 00:26:06.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undesignated store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tesco Finest Cheesecake Passion Fruit &amp; Raspbe...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0 days 00:26:06.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undesignated store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tesco Mixed Sized Organic Eggs 6 Pack</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0 days 00:26:06.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undesignated store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vanish Pet Expert Carpet Care Foam 600Ml</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0 days 00:26:06.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undesignated store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Tesco Clementine Or Sweet Easy Peeler Pack 600G</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0 days 00:26:06.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undesignated store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Tesco Oaty Rounds Biscuits 300G</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0 days 00:26:06.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undesignated store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Kraft Philadelphia Cheese 200 G Tub</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0 days 00:26:06.100000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Undesignated store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Tesco Garlic Baguette 205G</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0 days 00:50:31.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SOUTHWARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Elmlea Double Cream Alternative 284Ml</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0 days 00:26:06.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undesignated store</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Purchase__product__name  \\\n",
       "0    Koko Dairy Free Unsweetened Alternative Longli...   \n",
       "1                     Tesco Bunched Spring Onions 100G   \n",
       "2    Tesco Finest Cheesecake Passion Fruit & Raspbe...   \n",
       "3                Tesco Mixed Sized Organic Eggs 6 Pack   \n",
       "4             Vanish Pet Expert Carpet Care Foam 600Ml   \n",
       "..                                                 ...   \n",
       "438    Tesco Clementine Or Sweet Easy Peeler Pack 600G   \n",
       "439                    Tesco Oaty Rounds Biscuits 300G   \n",
       "440                Kraft Philadelphia Cheese 200 G Tub   \n",
       "441                         Tesco Garlic Baguette 205G   \n",
       "442              Elmlea Double Cream Alternative 284Ml   \n",
       "\n",
       "     Purchase__product__price    Purchase__timeStamp  \\\n",
       "0                        1.50 0 days 00:37:36.800000   \n",
       "1                        0.37 0 days 00:26:06.100000   \n",
       "2                        4.00 0 days 00:26:06.100000   \n",
       "3                        1.80 0 days 00:26:06.100000   \n",
       "4                        6.00 0 days 00:26:06.100000   \n",
       "..                        ...                    ...   \n",
       "438                      1.35 0 days 00:26:06.100000   \n",
       "439                      0.45 0 days 00:26:06.100000   \n",
       "440                      1.95 0 days 00:26:06.100000   \n",
       "441                      0.90 0 days 00:50:31.100000   \n",
       "442                      0.89 0 days 00:26:06.100000   \n",
       "\n",
       "     Purchase__product__quantity Purchase__storeName  \n",
       "0                            5.0           SOUTHWARK  \n",
       "1                            1.0  Undesignated store  \n",
       "2                            1.0  Undesignated store  \n",
       "3                            1.0  Undesignated store  \n",
       "4                            1.0  Undesignated store  \n",
       "..                           ...                 ...  \n",
       "438                          1.0  Undesignated store  \n",
       "439                          1.0  Undesignated store  \n",
       "440                          2.0  Undesignated store  \n",
       "441                          1.0           SOUTHWARK  \n",
       "442                          1.0  Undesignated store  \n",
       "\n",
       "[443 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#transform the data\n",
    "required_data = transform(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has been loaded to sqlite\n",
      "\n",
      "Data in Store_Purchase table has been loaded successfuly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/gy8jzz9n1yx5nmwnqmqyckbc0000gn/T/ipykernel_91918/1149635945.py:10: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  dataframe.to_sql(name=table_name, con=con, if_exists=\"replace\", index=False)\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "load(dataframe = required_data, database_name=\"Data_Pipeline\", table_name=\"Store_Purchase\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
